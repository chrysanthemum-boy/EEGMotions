import spidev
import time
from RPi import GPIO
import gpiod
import numpy as np
import torch
import torch.nn.functional as F
import torch.nn as nn
from collections import deque

# GPIOè®¾ç½®
GPIO.setwarnings(False)
GPIO.setmode(GPIO.BOARD)

# è®¾å¤‡é…ç½®
button_pin_1 = 26
button_pin_2 = 13

chip = gpiod.chip("0")
cs_line = chip.get_line(19)
cs_line_out = gpiod.line_request()
cs_line_out.consumer = "SPI_CS"
cs_line_out.request_type = gpiod.line_request.DIRECTION_OUTPUT
cs_line.request(cs_line_out)
cs_line.set_value(1)

line_1 = chip.get_line(button_pin_1)
line_2 = chip.get_line(button_pin_2)

button_line_1 = gpiod.line_request()
button_line_1.consumer = "Button"
button_line_1.request_type = gpiod.line_request.DIRECTION_INPUT
line_1.request(button_line_1)

button_line_2 = gpiod.line_request()
button_line_2.consumer = "Button"
button_line_2.request_type = gpiod.line_request.DIRECTION_INPUT
line_2.request(button_line_2)

# SPIåˆå§‹åŒ–
spi = spidev.SpiDev()
spi.open(0, 0)
spi.max_speed_hz = 4000000
spi.lsbfirst = False
spi.mode = 0b01
spi.bits_per_word = 8

spi_2 = spidev.SpiDev()
spi_2.open(0, 1)
spi_2.max_speed_hz = 4000000
spi_2.lsbfirst = False
spi_2.mode = 0b01
spi_2.bits_per_word = 8

# SPIå‘½ä»¤é›†
COMMANDS = {
    'wakeup': 0x02,
    'stop': 0x0A,
    'start': 0x08,
    'reset': 0x06,
    'sdatac': 0x11,
    'rdatac': 0x10,
    'rdata': 0x12
}


# åŠ è½½å¯¹åº”çš„æ¨¡å‹ç±»
class StressCNN(nn.Module):
    def __init__(self):
        super(StressCNN, self).__init__()

        # è¾“å…¥é€šé“ 1ï¼Œè¾“å‡ºé€šé“ 64ï¼Œå·ç§¯æ ¸ 3
        self.conv1 = nn.Conv1d(in_channels=1, out_channels=64, kernel_size=3)
        self.bn1 = nn.BatchNorm1d(64)
        self.pool1 = nn.MaxPool1d(kernel_size=2)
        self.drop1 = nn.Dropout(0.3)

        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3)
        self.bn2 = nn.BatchNorm1d(128)
        self.pool2 = nn.MaxPool1d(kernel_size=2)
        self.drop2 = nn.Dropout(0.3)

        self.fc1 = nn.Linear(128 * 2, 128)
        self.drop3 = nn.Dropout(0.5)
        self.fc2 = nn.Linear(128, 64)
        self.drop4 = nn.Dropout(0.5)
        self.fc3 = nn.Linear(64, 2)  # æœ€ç»ˆè¾“å‡º2ç±»

    def forward(self, x):
        # x shape: (batch_size, 1, 16)
        x = self.conv1(x)  # -> (batch_size, 64, 14)
        x = nn.functional.relu(x)
        x = self.bn1(x)
        x = self.pool1(x)  # -> (batch_size, 64, 7)
        x = self.drop1(x)

        x = self.conv2(x)  # -> (batch_size, 128, 5)
        x = nn.functional.relu(x)
        x = self.bn2(x)
        x = self.pool2(x)  # -> (batch_size, 128, 2)
        x = self.drop2(x)

        # å±•å¹³
        x = x.view(x.size(0), -1)  # -> (batch_size, 128*2)=256
        x = self.fc1(x)  # -> (batch_size, 128)
        x = nn.functional.relu(x)
        x = self.drop3(x)

        x = self.fc2(x)  # -> (batch_size, 64)
        x = nn.functional.relu(x)
        x = self.drop4(x)

        x = self.fc3(x)  # -> (batch_size, 2)
        return x


class StressCNNBiLSTM(nn.Module):
    def __init__(self):
        super(StressCNNBiLSTM, self).__init__()

        # CNN layers
        self.conv1 = nn.Conv1d(in_channels=1, out_channels=64, kernel_size=3)
        self.bn1 = nn.BatchNorm1d(64)  # æ·»åŠ äº†BatchNorm
        self.pool1 = nn.MaxPool1d(kernel_size=2)
        self.drop1 = nn.Dropout(0.3)

        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3)
        self.bn2 = nn.BatchNorm1d(128)  # æ·»åŠ äº†BatchNorm
        self.pool2 = nn.MaxPool1d(kernel_size=2)
        self.drop2 = nn.Dropout(0.3)

        # BiLSTM layers
        # å·ç§¯æ± åŒ–åçš„ç‰¹å¾å¤§å°: (batch_size, 128, 2)
        # è½¬ç½®åè¾“å…¥LSTMçš„å½¢çŠ¶: (batch_size, 2, 128)
        self.lstm1 = nn.LSTM(128, 64, bidirectional=True, batch_first=True)
        self.drop3 = nn.Dropout(0.5)

        # Fully connected layers
        self.fc1 = nn.Linear(64 * 2, 64)  # Flattened LSTM output
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 2)

    def forward(self, x):
        # CNN forward pass
        x = self.conv1(x)  # (batch_size, 64, 14)
        x = nn.functional.relu(x)
        x = self.bn1(x)  # æ·»åŠ BatchNorm
        x = self.pool1(x)  # (batch_size, 64, 7)
        x = self.drop1(x)

        x = self.conv2(x)  # (batch_size, 128, 5)
        x = nn.functional.relu(x)
        x = self.bn2(x)  # æ·»åŠ BatchNorm
        x = self.pool2(x)  # (batch_size, 128, 2)
        x = self.drop2(x)

        # Reshape to (batch_size, sequence_length, feature_size)
        x = x.permute(0, 2, 1)  # (batch_size, 2, 128)

        # BiLSTM forward pass
        x, _ = self.lstm1(x)  # (batch_size, 2, 128)
        x = self.drop3(x)

        # ä½¿ç”¨æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„è¾“å‡º
        x = x[:, -1, :]  # (batch_size, 64)
        x = self.fc1(x)  # (batch_size, 64)
        x = nn.functional.relu(x)
        x = self.fc2(x)  # (batch_size, 32)
        x = nn.functional.relu(x)
        x = self.fc3(x)  # (batch_size, 2)

        return x


# ä½¿ç”¨æ­¤ç±»å¦‚æœä½ ä½¿ç”¨çš„æ˜¯Transformeræ¨¡å‹
class StressTransformer(nn.Module):
    def __init__(self, input_dim=1, embed_dim=64, num_heads=4, ff_dim=128,
                 num_transformer_blocks=2, mlp_units=[64], dropout=0.3, mlp_dropout=0.3):
        super(StressTransformer, self).__init__()

        # åˆå§‹ç‰¹å¾åµŒå…¥å±‚
        self.embedding = nn.Linear(input_dim, embed_dim)

        # Transformerå—
        self.transformer_blocks = nn.ModuleList([
            TransformerBlock(embed_dim, num_heads, ff_dim, dropout)
            for _ in range(num_transformer_blocks)
        ])

        # MLPåˆ†ç±»å™¨
        layers = []
        for dim in mlp_units:
            layers.append(nn.Linear(embed_dim, dim))
            layers.append(nn.ReLU())
            layers.append(nn.Dropout(mlp_dropout))

        self.mlp = nn.Sequential(*layers)

        # è¾“å‡ºå±‚
        self.output_layer = nn.Linear(mlp_units[-1] if mlp_units else embed_dim, 2)

    def forward(self, x):
        # xçš„è¾“å…¥å½¢çŠ¶æ˜¯(batch_size, seq_len, input_dim)

        # æ˜ å°„åˆ°åµŒå…¥ç©ºé—´
        x = self.embedding(x)  # (batch_size, seq_len, embed_dim)

        # åº”ç”¨Transformerå—
        for transformer_block in self.transformer_blocks:
            x = transformer_block(x)

        # å…¨å±€å¹³å‡æ± åŒ– - å¯¹åºåˆ—ç»´åº¦è¿›è¡Œå¹³å‡
        x = x.mean(dim=1)  # (batch_size, embed_dim)

        # MLPåˆ†ç±»å™¨
        x = self.mlp(x)

        # è¾“å‡ºå±‚
        x = self.output_layer(x)

        return x


class TransformerBlock(nn.Module):
    def __init__(self, embed_dim, num_heads, ff_dim, dropout=0.1):
        super(TransformerBlock, self).__init__()

        # å¤šå¤´è‡ªæ³¨æ„åŠ›æœºåˆ¶
        self.att = nn.MultiheadAttention(embed_dim=embed_dim, num_heads=num_heads, dropout=dropout, batch_first=True)

        # å‰é¦ˆç¥ç»ç½‘ç»œ
        self.ffn = nn.Sequential(
            nn.Linear(embed_dim, ff_dim),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(ff_dim, embed_dim)
        )

        # Layer Normalization
        self.layernorm1 = nn.LayerNorm(embed_dim)
        self.layernorm2 = nn.LayerNorm(embed_dim)

        # Dropout
        self.dropout1 = nn.Dropout(dropout)
        self.dropout2 = nn.Dropout(dropout)

    def forward(self, x):
        # ç¬¬ä¸€ä¸ªå­å±‚ï¼šå¤šå¤´è‡ªæ³¨æ„åŠ› + æ®‹å·®è¿æ¥
        attn_output, _ = self.att(x, x, x)
        x = x + self.dropout1(attn_output)
        x = self.layernorm1(x)

        # ç¬¬äºŒä¸ªå­å±‚ï¼šå‰é¦ˆç¥ç»ç½‘ç»œ + æ®‹å·®è¿æ¥
        ffn_output = self.ffn(x)
        x = x + self.dropout2(ffn_output)
        x = self.layernorm2(x)

        return x


def send_command(spi_dev, command):
    spi_dev.xfer([command])


def write_register(spi_dev, register, data):
    write = 0x40
    register_write = write | register
    spi_dev.xfer([register_write, 0x00, data])


def read_eeg_data(spi_dev):
    output = spi_dev.readbytes(27)
    result = [0] * 8
    for a in range(3, 25, 3):
        voltage_1 = (output[a] << 8) | output[a + 1]
        voltage_1 = (voltage_1 << 8) | output[a + 2]

        data_test = 0x7FFFFF
        data_check = 0xFFFFFF

        convert_voltage = voltage_1 | data_test
        if convert_voltage == data_check:
            voltage_1_after_convert = (voltage_1 - 16777214)
        else:
            voltage_1_after_convert = voltage_1

        channel_num = int((a - 3) / 3)
        if 0 <= channel_num < 8:
            result[channel_num] = round(1000000 * 4.5 * (voltage_1_after_convert / 16777215), 2)

    return result


def initialize_spi_devices():
    for dev in [spi, spi_2]:
        send_command(dev, COMMANDS['wakeup'])
        send_command(dev, COMMANDS['stop'])
        send_command(dev, COMMANDS['reset'])
        send_command(dev, COMMANDS['sdatac'])

        write_register(dev, 0x14, 0x80)  # GPIO
        write_register(dev, 0x01, 0x96)  # config1
        write_register(dev, 0x02, 0xD4)  # config2
        write_register(dev, 0x03, 0xFF)  # config3

        for reg in [0x04, 0x0D, 0x0E, 0x0F, 0x10, 0x11, 0x15, 0x17]:
            write_register(dev, reg, 0x00)
        for ch in range(5, 13):
            write_register(dev, ch, 0x00)

        send_command(dev, COMMANDS['rdatac'])
        send_command(dev, COMMANDS['start'])


def real_time_prediction(model_path, model_type="CNN", window_size=10, threshold=0.5):
    """
    å®æ—¶é¢„æµ‹å‡½æ•°ï¼Œä½¿ç”¨æ»‘åŠ¨çª—å£å¹³å‡åŒ–é¢„æµ‹ç»“æœ

    Args:
        model_path: æ¨¡å‹æ–‡ä»¶è·¯å¾„
        model_type: æ¨¡å‹ç±»å‹ï¼Œ"CNN"æˆ–"Transformer"
        window_size: æ»‘åŠ¨çª—å£å¤§å°ï¼Œç”¨äºå¹³å‡é¢„æµ‹ç»“æœ
        threshold: é¢„æµ‹é˜ˆå€¼ï¼Œè¶…è¿‡æ­¤é˜ˆå€¼åˆ™åˆ¤æ–­ä¸ºstress
    """
    print(f"åŠ è½½ {model_type} æ¨¡å‹...")

    # æ ¹æ®æ¨¡å‹ç±»å‹åŠ è½½å¯¹åº”çš„æ¨¡å‹
    if model_type == "CNN":
        model = StressCNN()
        # åŠ è½½æ¨¡å‹å‚æ•°
        model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))
    elif model_type == "Transformer":
        # å¯¹äºTransformeræ¨¡å‹ï¼Œéœ€è¦ç¡®ä¿è¾“å…¥æ ¼å¼æ˜¯(batch_size, seq_len, feature_dim)
        model = StressTransformer()
        model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))
    elif model_type == "cnnbilstm":
        model = StressCNNBiLSTM()
        model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {model_type}")

    model.eval()

    print("åˆå§‹åŒ– EEG æ•°æ®ç¼“å†²åŒºå’Œ SPI...")
    # åˆ›å»ºä¸€ä¸ªç¼“å†²åŒºæ¥å­˜å‚¨æœ€æ–°çš„æ•°æ®ç‚¹
    data_buffer = []

    # åˆ›å»ºä¸€ä¸ªé˜Ÿåˆ—æ¥å­˜å‚¨æœ€è¿‘çš„é¢„æµ‹ç»“æœ
    prediction_window = deque(maxlen=window_size)

    # åˆ›å»ºå¹³æ»‘æ¦‚ç‡é˜Ÿåˆ—
    probability_window = deque(maxlen=window_size)

    initialize_spi_devices()

    print(f"å¼€å§‹å®æ—¶é¢„æµ‹ (ä½¿ç”¨ {window_size} å¸§æ»‘åŠ¨çª—å£)...")
    last_prediction = None
    consecutive_same = 0

    try:
        while True:
            # è¯»å–æ•°æ®
            data_1 = read_eeg_data(spi)
            data_2 = read_eeg_data(spi_2)
            current_data = data_1 + data_2

            if len(current_data) != 16:
                print(f"è­¦å‘Šï¼šEEGæ•°æ®é•¿åº¦å¼‚å¸¸ ({len(current_data)})")
                time.sleep(0.1)
                continue

            # å­˜å‚¨å½“å‰æ•°æ®ç‚¹
            data_buffer = current_data

            # å‡†å¤‡è¾“å…¥æ¨¡å‹çš„æ•°æ®
            if model_type == "CNN":
                # CNNæ¨¡å‹: [batch_size=1, channels=1, features=16]
                input_tensor = torch.FloatTensor(data_buffer).unsqueeze(0).unsqueeze(0)
            elif model_type == "Transformer":
                # Transformeræ¨¡å‹: [batch_size=1, seq_len=16, feature_dim=1]
                input_tensor = torch.FloatTensor(data_buffer).view(1, 16, 1)
            elif model_type == "cnnbilstm":
                input_tensor = torch.FloatTensor(data_buffer).unsqueeze(0).unsqueeze(0)

            # é¢„æµ‹
            with torch.no_grad():
                outputs = model(input_tensor)
                probabilities = torch.softmax(outputs, dim=1)
                stress_prob = probabilities[0][1].item()  # stressçš„æ¦‚ç‡

                # æ·»åŠ åˆ°æ¦‚ç‡çª—å£
                probability_window.append(stress_prob)

                # è®¡ç®—æ¦‚ç‡çš„å¹³å‡å€¼
                avg_probability = sum(probability_window) / len(probability_window)

                # æ ¹æ®å¹³å‡æ¦‚ç‡åˆ¤æ–­ç±»åˆ«
                predicted_class = 1 if avg_probability > threshold else 0
                prediction_window.append(predicted_class)

                # è®¡ç®—çª—å£å†…çš„å¤šæ•°ç±»åˆ«
                stress_count = sum(prediction_window)
                unstress_count = len(prediction_window) - stress_count

                # ç»¼åˆåˆ¤æ–­æœ€ç»ˆé¢„æµ‹ç»“æœ
                final_prediction = 1 if stress_count > unstress_count else 0
                final_confidence = stress_count / len(
                    prediction_window) if final_prediction == 1 else unstress_count / len(prediction_window)

                # è·Ÿè¸ªè¿ç»­ç›¸åŒçš„é¢„æµ‹æ¬¡æ•°
                if last_prediction is not None and final_prediction == last_prediction:
                    consecutive_same += 1
                else:
                    consecutive_same = 0
                last_prediction = final_prediction

                # æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
                print(f"\nå½“å‰stressæ¦‚ç‡: {stress_prob:.4f}, çª—å£å¹³å‡: {avg_probability:.4f}")
                print(
                    f"çª—å£ä¸­stresså æ¯”: {stress_count}/{len(prediction_window)} = {stress_count / len(prediction_window):.2f}")

                # ç¨³å®šæ€§æŒ‡æ ‡ - åªæœ‰å½“è¿ç»­5æ¬¡ä»¥ä¸Šç›¸åŒé¢„æµ‹æ‰æ˜¾ç¤ºæœ€ç»ˆç»“æœ
                if consecutive_same >= 5 or len(prediction_window) < window_size // 2:
                    verdict = "ğŸ”´ Stress" if final_prediction == 1 else "ğŸŸ¢ Unstress"
                    print(f"é¢„æµ‹ç»“æœ: {verdict} (ç½®ä¿¡åº¦: {final_confidence:.2f}, è¿ç»­{consecutive_same + 1}æ¬¡)")
                else:
                    print("ç¨³å®šä¸­...")

            time.sleep(0.2)  # æ§åˆ¶é‡‡æ ·é¢‘ç‡

    except KeyboardInterrupt:
        print("\nå®æ—¶é¢„æµ‹å·²ä¸­æ­¢")
    except Exception as e:
        print(f"\nå‘ç”Ÿé”™è¯¯ï¼š{e}")
    finally:
        return


def main():
    # ä½¿ç”¨ä½ ä¿å­˜çš„æ¨¡å‹è·¯å¾„
    model_path = 'cnn_bilstm_model_50epoch.pth'  # æˆ– 'stress_cnn_model_15epoch.pth'
    model_type = "cnnbilstm"  # æˆ– "CNN"

    # æ»‘åŠ¨çª—å£å¤§å° (å®æ—¶é¢„æµ‹æ—¶ç´¯ç§¯å¤šå°‘å¸§è¿›è¡Œå¹³å‡)
    window_size = 15

    # é¢„æµ‹é˜ˆå€¼
    threshold = 0.5

    try:
        real_time_prediction(
            model_path=model_path,
            model_type=model_type,
            window_size=window_size,
            threshold=threshold
        )
    except KeyboardInterrupt:
        print("å®æ—¶é¢„æµ‹å·²ä¸­æ­¢")
    finally:
        spi.close()
        spi_2.close()


if __name__ == "__main__":
    main()
